# mlops/serving/tensorflow-serving/models.config
# TensorFlow Serving Configuration for Goat Prediction Ultimate
# Production-grade multi-model configuration with advanced features

model_config_list {
  # ==================== FOOTBALL MODELS ====================
  
  # Football Match Winner Model (Primary)
  config {
    name: "football_match_winner"
    base_path: "/models/football/match_winner"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 3
        versions: 2
        versions: 1
      }
    }
    version_labels {
      key: "production"
      value: 3
    }
    version_labels {
      key: "canary"
      value: 2
    }
    version_labels {
      key: "stable"
      value: 1
    }
    model_warmup_options {
      batch_size: 32
      warmup_data_path: "/models/football/match_winner/warmup_data.pb"
      num_request_iterations: 100
    }
    optimization {
      execution_accelerators {
        cpu_execution_accelerator {
          name: "libtensorflow"
        }
        gpu_execution_accelerator {
          name: "tensorrt"
          parameters {
            key: "precision_mode"
            value: "FP16"
          }
          parameters {
            key: "max_workspace_size_bytes"
            value: "2147483648"
          }
          parameters {
            key: "minimum_segment_size"
            value: "3"
          }
        }
      }
      data_optimization {
        auto_mixed_precision: true
        auto_mixed_precision_cpu: true
      }
      input_output_optimization {
        grappler_optimization: true
        common_subgraph_elimination: true
        arithmetic_optimization: true
        dependency_optimization: true
        loop_optimization: true
        function_optimization: true
        debug_stripper: true
      }
    }
    max_batch_size: 128
    batch_timeout_micros: 1000
    enable_batching: true
    batching_parameters {
      max_batch_size: 128
      batch_timeout_micros: 1000
      max_enqueued_batches: 1000
      num_batch_threads: 8
      pad_variable_length_inputs: true
      allowed_batch_sizes: 1
      allowed_batch_sizes: 2
      allowed_batch_sizes: 4
      allowed_batch_sizes: 8
      allowed_batch_sizes: 16
      allowed_batch_sizes: 32
      allowed_batch_sizes: 64
      allowed_batch_sizes: 128
    }
    signature_name: "serving_default"
    monitoring_config {
      enable_performance_monitoring: true
      enable_model_monitoring: true
      enable_prediction_distribution_monitoring: true
      metrics {
        type: LATENCY
        sampling_rate: 0.1
      }
      metrics {
        type: THROUGHPUT
        sampling_rate: 1.0
      }
      metrics {
        type: ERROR_RATE
        sampling_rate: 1.0
      }
      metrics {
        type: MEMORY_USAGE
        sampling_rate: 0.01
      }
    }
    cache_config {
      cache_size_bytes: 1073741824  # 1GB
      cache_ttl_seconds: 3600
      eviction_policy: "LRU"
    }
  }

  # Football Over/Under 2.5 Goals Model
  config {
    name: "football_over_under"
    base_path: "/models/football/over_under"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 2
      }
    }
    version_labels {
      key: "production"
      value: 2
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/football/over_under/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 2000
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 2000
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    optimization {
      execution_accelerators {
        cpu_execution_accelerator {
          name: "libtensorflow"
        }
      }
    }
    signature_name: "serving_default"
  }

  # Football Both Teams to Score (BTTS) Model
  config {
    name: "football_btts"
    base_path: "/models/football/btts"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/football/btts/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 2000
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 2000
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    signature_name: "serving_default"
  }

  # Football Exact Score Model
  config {
    name: "football_exact_score"
    base_path: "/models/football/exact_score"
    model_platform: "tensorflow"
    model_version_policy {
      all {}
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/football/exact_score/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 3000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 3000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # Football Asian Handicap Model
  config {
    name: "football_asian_handicap"
    base_path: "/models/football/asian_handicap"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/football/asian_handicap/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 3000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 3000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # ==================== BASKETBALL MODELS ====================
  
  # Basketball Moneyline Model
  config {
    name: "basketball_moneyline"
    base_path: "/models/basketball/moneyline"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/basketball/moneyline/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 1500
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 1500
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    optimization {
      execution_accelerators {
        cpu_execution_accelerator {
          name: "libtensorflow"
        }
      }
    }
    signature_name: "serving_default"
  }

  # Basketball Point Spread Model
  config {
    name: "basketball_point_spread"
    base_path: "/models/basketball/point_spread"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/basketball/point_spread/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 1500
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 1500
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    signature_name: "serving_default"
  }

  # Basketball Total Points Model
  config {
    name: "basketball_total_points"
    base_path: "/models/basketball/total_points"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/basketball/total_points/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 1500
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 1500
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    signature_name: "serving_default"
  }

  # ==================== TENNIS MODELS ====================
  
  # Tennis Match Winner Model
  config {
    name: "tennis_match_winner"
    base_path: "/models/tennis/match_winner"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/tennis/match_winner/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 2000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 2000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    optimization {
      execution_accelerators {
        cpu_execution_accelerator {
          name: "libtensorflow"
        }
      }
    }
    signature_name: "serving_default"
  }

  # Tennis Set Betting Model
  config {
    name: "tennis_set_betting"
    base_path: "/models/tennis/set_betting"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/tennis/set_betting/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 2000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 2000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # Tennis Total Games Model
  config {
    name: "tennis_total_games"
    base_path: "/models/tennis/total_games"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/tennis/total_games/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 2000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 2000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # ==================== ESPORTS MODELS ====================
  
  # Esports Match Winner Model
  config {
    name: "esports_match_winner"
    base_path: "/models/esports/match_winner"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/esports/match_winner/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 1000
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 1000
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    optimization {
      execution_accelerators {
        cpu_execution_accelerator {
          name: "libtensorflow"
        }
      }
    }
    signature_name: "serving_default"
  }

  # Esports Map Winner Model
  config {
    name: "esports_map_winner"
    base_path: "/models/esports/map_winner"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/esports/map_winner/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 1000
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 1000
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    signature_name: "serving_default"
  }

  # Esports Total Kills Model
  config {
    name: "esports_total_kills"
    base_path: "/models/esports/total_kills"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 16
      warmup_data_path: "/models/esports/total_kills/warmup_data.pb"
      num_request_iterations: 50
    }
    max_batch_size: 64
    batch_timeout_micros: 1000
    enable_batching: true
    batching_parameters {
      max_batch_size: 64
      batch_timeout_micros: 1000
      max_enqueued_batches: 500
      num_batch_threads: 4
    }
    signature_name: "serving_default"
  }

  # ==================== ENSEMBLE MODELS ====================
  
  # Cross-Sport Ensemble Model
  config {
    name: "cross_sport_ensemble"
    base_path: "/models/ensemble/cross_sport"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/ensemble/cross_sport/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 3000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 3000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    optimization {
      execution_accelerators {
        cpu_execution_accelerator {
          name: "libtensorflow"
        }
        gpu_execution_accelerator {
          name: "tensorrt"
          parameters {
            key: "precision_mode"
            value: "FP16"
          }
        }
      }
    }
    signature_name: "serving_default"
  }

  # Football Multi-Market Ensemble
  config {
    name: "football_multi_market_ensemble"
    base_path: "/models/ensemble/football_multi_market"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/ensemble/football_multi_market/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 3000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 3000
      max_enqueued_batches: 250
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # ==================== REAL-TIME MODELS ====================
  
  # Live Football In-Play Model
  config {
    name: "live_football_inplay"
    base_path: "/models/realtime/live_football"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 1
      warmup_data_path: "/models/realtime/live_football/warmup_data.pb"
      num_request_iterations: 10
    }
    max_batch_size: 1  # Real-time, no batching
    batch_timeout_micros: 100
    enable_batching: false
    signature_name: "serving_default"
  }

  # Live Basketball In-Play Model
  config {
    name: "live_basketball_inplay"
    base_path: "/models/realtime/live_basketball"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 1
      }
    }
    model_warmup_options {
      batch_size: 1
      warmup_data_path: "/models/realtime/live_basketball/warmup_data.pb"
      num_request_iterations: 10
    }
    max_batch_size: 1
    batch_timeout_micros: 100
    enable_batching: false
    signature_name: "serving_default"
  }

  # ==================== ANALYTICS MODELS ====================
  
  # Feature Importance Model
  config {
    name: "feature_importance"
    base_path: "/models/analytics/feature_importance"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/analytics/feature_importance/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 5000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 5000
      max_enqueued_batches: 100
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # Anomaly Detection Model
  config {
    name: "anomaly_detection"
    base_path: "/models/analytics/anomaly_detection"
    model_platform: "tensorflow"
    model_version_policy {
      latest {
        num_versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/analytics/anomaly_detection/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 5000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 5000
      max_enqueued_batches: 100
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # Model Drift Detection
  config {
    name: "drift_detection"
    base_path: "/models/analytics/drift_detection"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 8
      warmup_data_path: "/models/analytics/drift_detection/warmup_data.pb"
      num_request_iterations: 25
    }
    max_batch_size: 32
    batch_timeout_micros: 5000
    enable_batching: true
    batching_parameters {
      max_batch_size: 32
      batch_timeout_micros: 5000
      max_enqueued_batches: 100
      num_batch_threads: 2
    }
    signature_name: "serving_default"
  }

  # ==================== SUPPORTING MODELS ====================
  
  # Input Validation Model
  config {
    name: "input_validation"
    base_path: "/models/support/input_validation"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 32
      warmup_data_path: "/models/support/input_validation/warmup_data.pb"
      num_request_iterations: 100
    }
    max_batch_size: 128
    batch_timeout_micros: 500
    enable_batching: true
    batching_parameters {
      max_batch_size: 128
      batch_timeout_micros: 500
      max_enqueued_batches: 1000
      num_batch_threads: 8
    }
    signature_name: "serving_default"
  }

  # Feature Transformer Model
  config {
    name: "feature_transformer"
    base_path: "/models/support/feature_transformer"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 2
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 32
      warmup_data_path: "/models/support/feature_transformer/warmup_data.pb"
      num_request_iterations: 100
    }
    max_batch_size: 128
    batch_timeout_micros: 500
    enable_batching: true
    batching_parameters {
      max_batch_size: 128
      batch_timeout_micros: 500
      max_enqueued_batches: 1000
      num_batch_threads: 8
    }
    signature_name: "serving_default"
  }

  # Output Post-Processor
  config {
    name: "output_postprocessor"
    base_path: "/models/support/output_postprocessor"
    model_platform: "tensorflow"
    model_version_policy {
      specific {
        versions: 1
      }
    }
    model_warmup_options {
      batch_size: 32
      warmup_data_path: "/models/support/output_postprocessor/warmup_data.pb"
      num_request_iterations: 100
    }
    max_batch_size: 128
    batch_timeout_micros: 500
    enable_batching: true
    batching_parameters {
      max_batch_size: 128
      batch_timeout_micros: 500
      max_enqueued_batches: 1000
      num_batch_threads: 8
    }
    signature_name: "serving_default"
  }

  # ==================== GLOBAL CONFIGURATION ====================
  
  # Global model server configuration
  model_server_config {
    gpu_memory_fraction: 0.8
    enable_model_warmup: true
    enable_batching: true
    batching_parameters {
      max_batch_size: 128
      batch_timeout_micros: 1000
      max_enqueued_batches: 10000
      num_batch_threads: 16
      thread_pool_name_prefix: "batch_thread"
    }
    model_config_file_poll_wait_seconds: 30
    file_system_poll_wait_seconds: 30
    enable_model_management: true
    model_management_config {
      enable_model_version_policy: true
      enable_version_labels: true
      enable_model_warmup: true
      model_warmup_options {
        enable_warmup: true
        warmup_data_dir: "/models/warmup_data"
        num_warmup_threads: 4
      }
    }
    monitoring_config {
      enable_monitoring: true
      monitoring_prometheus_port: 8000
      monitoring_sampling_rate: 0.1
      enable_perf_model_monitoring: true
      enable_prediction_distribution_monitoring: true
      monitoring_metrics {
        type: LATENCY
        sampling_rate: 0.1
      }
      monitoring_metrics {
        type: THROUGHPUT
        sampling_rate: 1.0
      }
      monitoring_metrics {
        type: ERROR_RATE
        sampling_rate: 1.0
      }
      monitoring_metrics {
        type: GPU_UTILIZATION
        sampling_rate: 0.1
      }
      monitoring_metrics {
        type: MEMORY_USAGE
        sampling_rate: 0.01
      }
      monitoring_metrics {
        type: CACHE_HIT_RATIO
        sampling_rate: 1.0
      }
    }
    session_config {
      intra_op_parallelism_threads: 8
      inter_op_parallelism_threads: 8
      use_per_session_threads: true
      placement_period: 0
      gpu_options {
        allow_growth: true
        per_process_gpu_memory_fraction: 0.8
        allocator_type: "BFC"
        deferred_deletion_bytes: 0
        visible_device_list: "0"
        polling_active_delay_usecs: 10
        polling_inactive_delay_msecs: 1000
        force_gpu_compatible: true
        experimental {
          num_dev_to_dev_copy_streams: 1
          timestamped_allocator: false
        }
      }
      graph_options {
        enable_recv_scheduling: true
        optimizer_options {
          opt_level: 1
          do_common_subexpression_elimination: true
          do_constant_folding: true
          do_function_inlining: true
          global_jit_level: 1
        }
        rewrite_options {
          layout_optimizer: 1
          constant_folding: 1
          shape_optimization: 1
          remapping: 1
          arithmetic_optimization: 1
          dependency_optimization: 1
          loop_optimization: 1
          function_optimization: 1
          debug_stripper: 1
          disable_model_pruning: 0
          scoped_allocator_optimization: 1
          pin_to_host_optimization: 1
          implementation_selector: 1
          auto_mixed_precision: 1
          auto_mixed_precision_mkl: 0
          auto_mixed_precision_onednn_bfloat16: 0
        }
      }
      rpc_options {
        compression_algorithm: "NONE"
        compression_level: 0
        cache_rpc_response: false
        disable_session_connection_sharing: false
        num_channels_per_target: 1
      }
      cluster_def {
        job {
          name: "worker"
          tasks {
            key: 0
            value: "localhost:2222"
          }
        }
      }
    }
    saved_model_tags: "serve"
    signature_name: "serving_default"
    version: 1
  }

  # Performance optimization settings
  optimization_settings {
    enable_grappler_optimizations: true
    enable_xla: true
    enable_mkl: true
    enable_cuda_graph: true
    enable_tensorrt: true
    enable_auto_mixed_precision: true
    enable_onednn: true
    optimization_level: 1
    num_cpu_threads: 8
    num_gpu_streams: 4
    max_queue_size: 10000
    batch_timeout_micros: 1000
    max_batch_size: 128
    batch_thread_pool_size: 16
    enable_dynamic_batching: true
    enable_priority_batching: true
    enable_model_warmup: true
    warmup_batch_size: 32
    warmup_num_iterations: 100
    enable_caching: true
    cache_size_mb: 1024
    cache_ttl_seconds: 3600
    enable_compression: true
    compression_algorithm: "SNAPPY"
    enable_encryption: false
    encryption_key: ""
  }

  # Security configuration
  security_config {
    enable_authentication: true
    authentication_type: "JWT"
    jwt_secret_key_path: "/etc/secrets/jwt_secret.key"
    enable_authorization: true
    authorization_policy_path: "/etc/config/authorization_policy.json"
    enable_ssl: true
    ssl_certificate_path: "/etc/ssl/certs/tls.crt"
    ssl_private_key_path: "/etc/ssl/private/tls.key"
    ssl_ca_certificate_path: "/etc/ssl/certs/ca.crt"
    enable_rate_limiting: true
    rate_limit_requests_per_second: 1000
    rate_limit_burst_size: 100
    enable_ip_filtering: true
    allowed_ip_ranges: "10.0.0.0/8,172.16.0.0/12,192.168.0.0/16"
    enable_audit_logging: true
    audit_log_path: "/var/log/tensorflow-serving/audit.log"
    enable_data_encryption: true
    encryption_key_path: "/etc/secrets/encryption.key"
    enable_secure_model_loading: true
    model_signature_verification: true
    signature_public_key_path: "/etc/secrets/model_signature.pub"
  }

  # Monitoring and observability
  monitoring_config {
    enable_prometheus: true
    prometheus_port: 8000
    prometheus_endpoint: "/metrics"
    enable_jaeger: true
    jaeger_endpoint: "jaeger-collector.monitoring.svc.cluster.local:14268"
    jaeger_sampling_rate: 0.1
    enable_structured_logging: true
    log_format: "JSON"
    log_level: "INFO"
    log_rotation_policy {
      max_file_size_mb: 100
      max_files: 10
      rotation_interval_hours: 24
    }
    enable_health_checks: true
    health_check_endpoint: "/health"
    health_check_interval_seconds: 30
    enable_performance_monitoring: true
    performance_metrics_interval_seconds: 60
    enable_resource_monitoring: true
    resource_metrics_interval_seconds: 30
    enable_business_metrics: true
    business_metrics {
      prediction_accuracy: true
      prediction_latency: true
      throughput: true
      error_rate: true
      cache_hit_ratio: true
      model_confidence: true
      feature_completeness: true
    }
  }

  # Model management and lifecycle
  model_management_config {
    enable_auto_version_policy: true
    version_policy_type: "LATEST_N"
    latest_n_versions: 3
    enable_version_labels: true
    default_version_label: "production"
    enable_model_warmup: true
    warmup_data_dir: "/models/warmup_data"
    warmup_batch_size: 32
    warmup_num_iterations: 100
    enable_model_preloading: true
    preload_models: ["football_match_winner", "basketball_moneyline"]
    enable_model_caching: true
    cache_size_mb: 1024
    cache_ttl_seconds: 3600
    enable_model_encryption: false
    encryption_key_path: ""
    enable_model_signature_verification: true
    signature_public_key_path: "/etc/secrets/model_signature.pub"
    enable_model_backup: true
    backup_interval_hours: 24
    backup_retention_days: 30
    backup_storage_path: "s3://goat-prediction-backups/models/"
    enable_model_rollback: true
    rollback_versions_to_keep: 5
    enable_model_health_check: true
    health_check_interval_minutes: 5
    health_check_timeout_seconds: 30
  }

  # Resource management
  resource_management_config {
    cpu_allocation {
      requests: "2"
      limits: "4"
      cpu_set: "0-7"
    }
    memory_allocation {
      requests: "4Gi"
      limits: "8Gi"
      hugepages: false
    }
    gpu_allocation {
      enabled: true
      count: 1
      memory_fraction: 0.8
      visible_devices: "0"
    }
    storage_allocation {
      model_storage: "100Gi"
      cache_storage: "10Gi"
      log_storage: "20Gi"
    }
    network_allocation {
      bandwidth_limit: "1G"
      connection_limit: 10000
      keepalive_timeout: 65
    }
  }

  # Custom endpoints and routing
  custom_endpoints {
    endpoint {
      name: "predict"
      path: "/v1/models/{model_name}/versions/{model_version}:predict"
      method: "POST"
      timeout_seconds: 30
      rate_limit: 1000
      authentication_required: true
    }
    endpoint {
      name: "classify"
      path: "/v1/models/{model_name}/versions/{model_version}:classify"
      method: "POST"
      timeout_seconds: 30
      rate_limit: 1000
      authentication_required: true
    }
    endpoint {
      name: "regress"
      path: "/v1/models/{model_name}/versions/{model_version}:regress"
      method: "POST"
      timeout_seconds: 30
      rate_limit: 1000
      authentication_required: true
    }
    endpoint {
      name: "metadata"
      path: "/v1/models/{model_name}/versions/{model_version}/metadata"
      method: "GET"
      timeout_seconds: 10
      rate_limit: 100
      authentication_required: false
    }
    endpoint {
      name: "health"
      path: "/health"
      method: "GET"
      timeout_seconds: 5
      rate_limit: 10
      authentication_required: false
    }
    endpoint {
      name: "metrics"
      path: "/metrics"
      method: "GET"
      timeout_seconds: 5
      rate_limit: 10
      authentication_required: false
    }
    endpoint {
      name: "status"
      path: "/v1/models/{model_name}/versions/{model_version}/status"
      method: "GET"
      timeout_seconds: 10
      rate_limit: 100
      authentication_required: true
    }
  }

  # Model routing and load balancing
  routing_config {
    enable_load_balancing: true
    load_balancing_algorithm: "ROUND_ROBIN"
    enable_circuit_breaker: true
    circuit_breaker_threshold: 0.5
    circuit_breaker_timeout_seconds: 60
    enable_retry: true
    max_retries: 3
    retry_delay_millis: 100
    enable_timeout: true
    default_timeout_seconds: 30
    enable_health_check: true
    health_check_interval_seconds: 30
    enable_sticky_sessions: true
    session_timeout_seconds: 3600
    enable_canary_routing: true
    canary_traffic_percentage: 10
    enable_ab_testing: true
    ab_test_groups: ["control", "treatment"]
  }

  # Model warmup configuration
  warmup_config {
    enable_warmup: true
    warmup_data_path: "/models/warmup_data"
    warmup_batch_sizes: [1, 8, 16, 32, 64, 128]
    warmup_num_iterations: 100
    warmup_threads: 4
    warmup_timeout_seconds: 300
    warmup_models: ["football_match_winner", "basketball_moneyline", "tennis_match_winner"]
    warmup_signatures: ["serving_default", "classification", "regression"]
  }

  # Caching configuration
  cache_config {
    enable_caching: true
    cache_backend: "REDIS"
    redis_endpoint: "redis://redis-cache.ml-production.svc.cluster.local:6379"
    cache_ttl_seconds: 3600
    cache_max_size_mb: 1024
    cache_eviction_policy: "LRU"
    enable_compression: true
    compression_algorithm: "SNAPPY"
    enable_encryption: false
    encryption_key_path: ""
    cache_stats_interval_seconds: 60
  }

  # Logging and tracing
  logging_config {
    log_level: "INFO"
    log_format: "JSON"
    log_rotation {
      max_file_size_mb: 100
      max_files: 10
      rotation_interval_hours: 24
    }
    enable_structured_logging: true
    enable_audit_logging: true
    audit_log_path: "/var/log/tensorflow-serving/audit.log"
    enable_tracing: true
    tracing_backend: "JAEGER"
    jaeger_endpoint: "jaeger-collector.monitoring.svc.cluster.local:14268"
    tracing_sampling_rate: 0.1
    enable_metrics: true
    metrics_backend: "PROMETHEUS"
    prometheus_port: 8000
    metrics_endpoint: "/metrics"
  }

  # Model version management
  version_management {
    enable_auto_versioning: true
    version_format: "SEMANTIC"
    keep_versions: 5
    auto_cleanup_old_versions: true
    cleanup_threshold_days: 30
    enable_version_labels: true
    default_labels: ["production", "staging", "canary"]
    enable_version_promotion: true
    promotion_criteria: {
      accuracy_threshold: 0.85
      latency_threshold_ms: 100
      error_rate_threshold: 0.01
    }
    enable_version_rollback: true
    rollback_versions_to_keep: 3
  }

  # Performance tuning
  performance_tuning {
    enable_autotune: true
    autotune_interval_minutes: 60
    target_latency_ms: 50
    target_throughput_rps: 1000
    enable_dynamic_batching: true
    max_batch_size: 128
    batch_timeout_ms: 100
    enable_memory_optimization: true
    memory_limit_mb: 8192
    enable_gpu_optimization: true
    gpu_memory_fraction: 0.8
    enable_cpu_optimization: true
    cpu_threads: 8
    enable_model_optimization: true
    optimization_level: 2
    enable_caching: true
    cache_size_mb: 1024
  }

  # Security hardening
  security_hardening {
    enable_seccomp: true
    seccomp_profile_path: "/etc/seccomp/tensorflow-serving.json"
    enable_apparmor: true
    apparmor_profile: "tensorflow-serving"
    enable_selinux: true
    selinux_context: "system_u:system_r:container_t:s0"
    drop_capabilities: ["ALL"]
    add_capabilities: []
    read_only_root_filesystem: true
    allow_privilege_escalation: false
    run_as_non_root: true
    run_as_user: 1000
    run_as_group: 1000
    enable_network_policies: true
    network_policy_path: "/etc/network-policies/tensorflow-serving.json"
  }

  # Compliance and auditing
  compliance_config {
    enable_gdpr_compliance: true
    data_retention_days: 365
    enable_pci_compliance: true
    pci_audit_interval_days: 90
    enable_hipaa_compliance: false
    enable_soc2_compliance: true
    soc2_audit_interval_days: 180
    enable_audit_logging: true
    audit_log_retention_days: 365
    enable_data_encryption: true
    encryption_standard: "AES-256-GCM"
    enable_access_logging: true
    access_log_retention_days: 90
  }

  # Backup and disaster recovery
  backup_config {
    enable_backup: true
    backup_schedule: "0 2 * * *"  # Daily at 2 AM
    backup_retention_days: 30
    backup_storage: "S3"
    s3_bucket: "goat-prediction-backups"
    s3_prefix: "tensorflow-serving/models/"
    enable_incremental_backup: true
    incremental_backup_interval_hours: 6
    enable_backup_encryption: true
    backup_encryption_key_path: "/etc/secrets/backup.key"
    enable_backup_verification: true
    backup_verification_interval_days: 7
  }

  # Custom model parameters (model-specific settings)
  custom_model_parameters {
    # Football match winner model specific parameters
    football_match_winner {
      confidence_threshold: 0.65
      min_features_required: 20
      feature_normalization: true
      ensemble_weight: 0.4
      cache_enabled: true
      cache_ttl_seconds: 300
    }
    
    # Basketball moneyline model specific parameters
    basketball_moneyline {
      confidence_threshold: 0.60
      min_features_required: 15
      feature_normalization: true
      ensemble_weight: 0.3
      cache_enabled: true
      cache_ttl_seconds: 300
    }
    
    # Real-time models specific parameters
    live_football_inplay {
      confidence_threshold: 0.55
      min_features_required: 10
      feature_normalization: false
      ensemble_weight: 0.1
      cache_enabled: false
      prediction_timeout_ms: 50
    }
  }
}

# ==================== DOCUMENTATION ====================
#
# TensorFlow Serving Configuration for Goat Prediction Ultimate
# 
# This configuration file defines:
# 1. 20+ models across multiple sports and markets
# 2. Version management with production/canary/stable labels
# 3. Advanced batching and optimization settings
# 4. Comprehensive monitoring and observability
# 5. Security and compliance configurations
# 6. Performance tuning and resource management
# 7. Backup and disaster recovery plans
#
# Model Categories:
# - Football: Match winner, over/under, BTTS, exact score, Asian handicap
# - Basketball: Moneyline, point spread, total points
# - Tennis: Match winner, set betting, total games
# - Esports: Match winner, map winner, total kills
# - Ensemble: Cross-sport, multi-market
# - Real-time: In-play predictions
# - Analytics: Feature importance, anomaly detection, drift detection
# - Support: Input validation, feature transformer, output post-processor
#
# Key Features:
# - GPU acceleration with TensorRT optimization
# - Dynamic batching for throughput optimization
# - Model warmup for cold start reduction
# - Caching with Redis backend
# - Comprehensive monitoring with Prometheus/Jaeger
# - Security with JWT authentication and SSL
# - Canary deployments and A/B testing
# - Automated version management
# - Compliance with GDPR/PCI/SOC2
#
# Deployment Commands:
# 1. Apply configuration: kubectl apply -f models.config
# 2. Verify deployment: kubectl get pods -n ml-production -l app=tensorflow-serving
# 3. Check logs: kubectl logs -f deployment/tensorflow-serving -n ml-production
# 4. Test endpoint: curl -X POST http://tensorflow-serving.ml-production.svc.cluster.local:8501/v1/models/football_match_winner:predict -d @test_request.json
#
# Maintenance:
# - Regular model updates via CI/CD pipeline
# - Monitor performance metrics and alerts
# - Regular security audits and compliance checks
# - Backup verification and disaster recovery testing
#
# Support:
# - Documentation: https://docs.goat-prediction.com/tensorflow-serving
# - Runbooks: https://runbooks.goat-prediction.com/tensorflow-serving
# - Slack: #tensorflow-serving-support
# - Email: tensorflow-serving@goat-prediction.com
#
# Version: 3.0.0
# Last Updated: 2025-15-01
# Maintainer: ML Engineering Team
# SLA: 99.95% availability
