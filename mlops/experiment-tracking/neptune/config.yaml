# üêê GOAT-PREDICTION ULTIMATE - NEPTUNE.AI CONFIGURATION
# Version: 2.0.0
# Description: Neptune.ai configuration for experiment tracking, model registry, and MLOps
# Author: GOAT-PREDICTION Team
# Date: $(date)

# =============================================================================
# NEPTUNE CORE CONFIGURATION
# =============================================================================

# Project Configuration
project: "goat-prediction/goat-prediction-ultimate"
api_token: "${NEPTUNE_API_TOKEN}"

# Experiment Configuration
name: "${EXPERIMENT_NAME:-goat-experiment-${TIMESTAMP}}"
description: "${EXPERIMENT_DESCRIPTION:-GOAT-PREDICTION ${SPORT} ${MARKET_TYPE} model training}"
tags:
  - "${ENVIRONMENT:-development}"
  - "${SPORT:-football}"
  - "${MARKET_TYPE:-match_winner}"
  - "${MODEL_TYPE:-transformer}"
  - "v${MODEL_VERSION:-1.0.0}"

# Source Code Tracking
source_files:
  - "**/*.py"
  - "**/*.ipynb"
  - "**/*.yaml"
  - "**/*.yml"
  - "**/*.json"
  
# Git Integration
git_info:
  enabled: true
  email: "${GIT_EMAIL}"
  commit: "${GIT_COMMIT}"
  branch: "${GIT_BRANCH}"
  remote: "${GIT_REMOTE:-origin}"

# =============================================================================
# EXPERIMENT METADATA
# =============================================================================

# System Information
metadata:
  hostname: "${HOSTNAME}"
  username: "${USER}"
  platform: "${PLATFORM}"
  python_version: "${PYTHON_VERSION}"
  
  # Hardware Info
  cpu_count: "${CPU_COUNT}"
  cpu_model: "${CPU_MODEL}"
  gpu_count: "${GPU_COUNT}"
  gpu_model: "${GPU_MODEL}"
  total_memory_gb: "${TOTAL_MEMORY_GB}"
  available_memory_gb: "${AVAILABLE_MEMORY_GB}"
  
  # Software Info
  pytorch_version: "${PYTORCH_VERSION}"
  tensorflow_version: "${TENSORFLOW_VERSION}"
  cuda_version: "${CUDA_VERSION}"
  cudnn_version: "${CUDNN_VERSION}"

# =============================================================================
# HYPERPARAMETERS CONFIGURATION
# =============================================================================

# Model Architecture Parameters
parameters:
  
  # Model Configuration
  model:
    type: "${MODEL_TYPE:-transformer}"
    version: "${MODEL_VERSION:-1.0.0}"
    hidden_size: ${HIDDEN_SIZE:-256}
    num_layers: ${NUM_LAYERS:-6}
    num_heads: ${NUM_HEADS:-8}
    dropout_rate: ${DROPOUT_RATE:-0.1}
    activation: "${ACTIVATION:-gelu}"
    optimizer: "${OPTIMIZER:-adamw}"
    loss_function: "${LOSS_FUNCTION:-cross_entropy}"
    
  # Training Configuration
  training:
    batch_size: ${BATCH_SIZE:-32}
    learning_rate: ${LEARNING_RATE:-0.001}
    weight_decay: ${WEIGHT_DECAY:-0.01}
    scheduler: "${SCHEDULER:-cosine}"
    warmup_steps: ${WARMUP_STEPS:-1000}
    max_epochs: ${MAX_EPOCHS:-100}
    gradient_clip: ${GRADIENT_CLIP:-1.0}
    early_stopping_patience: ${EARLY_STOPPING_PATIENCE:-10}
    checkpoint_frequency: ${CHECKPOINT_FREQUENCY:-10}
    
  # Data Configuration
  data:
    sport: "${SPORT:-football}"
    market_type: "${MARKET_TYPE:-match_winner}"
    feature_set: "${FEATURE_SET:-advanced}"
    sequence_length: ${SEQUENCE_LENGTH:-128}
    num_features: ${NUM_FEATURES:-100}
    train_split: ${TRAIN_SPLIT:-0.7}
    val_split: ${VAL_SPLIT:-0.15}
    test_split: ${TEST_SPLIT:-0.15}
    augmentations: ${AUGMENTATIONS:-false}
    
  # Sports Specific Parameters
  sports:
    football:
      include_xg: ${INCLUDE_XG:-true}
      include_possession: ${INCLUDE_POSSESSION:-true}
      include_shots: ${INCLUDE_SHOTS:-true}
      include_corners: ${INCLUDE_CORNERS:-true}
      include_cards: ${INCLUDE_CARDS:-true}
      
    basketball:
      include_points: ${INCLUDE_POINTS:-true}
      include_rebounds: ${INCLUDE_REBOUNDS:-true}
      include_assists: ${INCLUDE_ASSISTS:-true}
      include_steals: ${INCLUDE_STEALS:-true}
      include_blocks: ${INCLUDE_BLOCKS:-true}
      
    tennis:
      include_aces: ${INCLUDE_ACES:-true}
      include_double_faults: ${INCLUDE_DOUBLE_FAULTS:-true}
      include_break_points: ${INCLUDE_BREAK_POINTS:-true}
      include_service_points: ${INCLUDE_SERVICE_POINTS:-true}
      
  # Random Seeds
  seeds:
    random_seed: ${RANDOM_SEED:-42}
    data_seed: ${DATA_SEED:-123}
    model_seed: ${MODEL_SEED:-456}
    numpy_seed: ${NUMPY_SEED:-789}
    torch_seed: ${TORCH_SEED:-101112}

# =============================================================================
# METRICS TRACKING CONFIGURATION
# =============================================================================

# Training Metrics
metrics:
  
  # Loss Metrics
  loss:
    train:
      log_frequency: 10  # steps
      smoothing: 0.9
    validation:
      log_frequency: 1   # epoch
    test:
      log_once: true
      
  # Accuracy Metrics
  accuracy:
    train:
      log_frequency: 10
    validation:
      log_frequency: 1
    test:
      log_once: true
      
  # Precision, Recall, F1
  classification:
    train:
      log_frequency: 50
    validation:
      log_frequency: 1
    test:
      log_once: true
      
  # AUC-ROC
  auc:
    validation:
      log_frequency: 1
    test:
      log_once: true
      
  # Business Metrics
  business:
    roi:
      log_frequency: 1
      goal: 0.15
    profit_factor:
      log_frequency: 1
      goal: 1.5
    sharpe_ratio:
      log_frequency: 1
      goal: 2.0
    win_rate:
      log_frequency: 1
      goal: 0.60
    max_drawdown:
      log_frequency: 1
      goal: 0.10

# Custom Metrics Configuration
custom_metrics:
  
  # Football Specific Metrics
  football:
    - name: "expected_goals_correlation"
      description: "Correlation between predicted and actual xG"
      goal: 0.8
      maximize: true
      
    - name: "clean_sheet_accuracy"
      description: "Accuracy in predicting clean sheets"
      goal: 0.75
      maximize: true
      
    - name: "btts_accuracy"
      description: "Both teams to score prediction accuracy"
      goal: 0.7
      maximize: true
      
    - name: "over_under_accuracy"
      description: "Over/Under prediction accuracy"
      goal: 0.65
      maximize: true
      
    - name: "correct_score_accuracy"
      description: "Exact score prediction accuracy"
      goal: 0.15
      maximize: true
      
  # Basketball Specific Metrics
  basketball:
    - name: "point_spread_mae"
      description: "Mean absolute error for point spread"
      goal: 4.0
      minimize: true
      
    - name: "total_points_mae"
      description: "Mean absolute error for total points"
      goal: 8.0
      minimize: true
      
    - name: "moneyline_accuracy"
      description: "Moneyline prediction accuracy"
      goal: 0.65
      maximize: true
      
  # Tennis Specific Metrics
  tennis:
    - name: "match_winner_accuracy"
      description: "Match winner prediction accuracy"
      goal: 0.75
      maximize: true
      
    - name: "set_betting_accuracy"
      description: "Set betting prediction accuracy"
      goal: 0.60
      maximize: true
      
    - name: "total_games_accuracy"
      description: "Total games prediction accuracy"
      goal: 0.65
      maximize: true

# =============================================================================
# MODEL REGISTRY CONFIGURATION
# =============================================================================

model_registry:
  
  # Registry Settings
  enabled: true
  project: "goat-prediction/goat-model-registry"
  
  # Model Stages
  stages:
    - name: "development"
      description: "Model under development"
      color: "#FF6B6B"
      
    - name: "staging"
      description: "Model ready for testing"
      color: "#4ECDC4"
      
    - name: "production"
      description: "Model deployed in production"
      color: "#45B7D1"
      
    - name: "archived"
      description: "Model archived"
      color: "#96CEB4"
  
  # Versioning
  versioning:
    scheme: "semantic"  # semantic, incremental, timestamp
    auto_increment: true
    prefix: "v"
    
  # Model Metadata
  metadata:
    framework: "${FRAMEWORK:-pytorch}"
    task_type: "${TASK_TYPE:-classification}"
    input_format: "${INPUT_FORMAT:-tensor}"
    output_format: "${OUTPUT_FORMAT:-probabilities}"
    
    # Sports Metadata
    sport: "${SPORT:-football}"
    league: "${LEAGUE:-premier_league}"
    season: "${SEASON:-2023-2024}"
    market: "${MARKET_TYPE:-match_winner}"
    
    # Performance Metadata
    training_time_hours: "${TRAINING_TIME_HOURS}"
    inference_latency_ms: "${INFERENCE_LATENCY_MS}"
    model_size_mb: "${MODEL_SIZE_MB}"
    
    # Business Metadata
    expected_roi: "${EXPECTED_ROI}"
    expected_win_rate: "${EXPECTED_WIN_RATE}"
    risk_level: "${RISK_LEVEL:-medium}"
    
    # Compliance
    data_sources: "${DATA_SOURCES:-statsbomb,opta,sportradar}"
    training_date: "${TRAINING_DATE}"
    last_updated: "${LAST_UPDATED}"
    license: "${LICENSE:-proprietary}"
    privacy_level: "${PRIVACY_LEVEL:-confidential}"
  
  # Model Artifacts
  artifacts:
    
    # Model Files
    model_file:
      path: "./models/${MODEL_NAME}.pt"
      description: "Trained model weights"
      format: "pytorch"
      
    model_config:
      path: "./configs/${MODEL_NAME}_config.yaml"
      description: "Model configuration"
      format: "yaml"
      
    # Preprocessing
    preprocessor:
      path: "./preprocessors/${MODEL_NAME}_preprocessor.pkl"
      description: "Feature preprocessor"
      format: "pickle"
      
    scaler:
      path: "./preprocessors/${MODEL_NAME}_scaler.pkl"
      description: "Feature scaler"
      format: "pickle"
      
    encoder:
      path: "./preprocessors/${MODEL_NAME}_encoder.pkl"
      description: "Label encoder"
      format: "pickle"
      
    # Analysis Files
    feature_importance:
      path: "./analysis/${MODEL_NAME}_feature_importance.png"
      description: "Feature importance visualization"
      format: "png"
      
    confusion_matrix:
      path: "./analysis/${MODEL_NAME}_confusion_matrix.png"
      description: "Confusion matrix"
      format: "png"
      
    roc_curve:
      path: "./analysis/${MODEL_NAME}_roc_curve.png"
      description: "ROC curve"
      format: "png"
      
    # Reports
    performance_report:
      path: "./reports/${MODEL_NAME}_performance_report.html"
      description: "Model performance report"
      format: "html"
      
    business_report:
      path: "./reports/${MODEL_NAME}_business_report.pdf"
      description: "Business impact analysis"
      format: "pdf"
      
    # Deployment Files
    dockerfile:
      path: "./deployment/Dockerfile.${MODEL_NAME}"
      description: "Docker configuration"
      format: "dockerfile"
      
    inference_script:
      path: "./deployment/inference_${MODEL_NAME}.py"
      description: "Inference script"
      format: "python"

# =============================================================================
# DATASET VERSIONING CONFIGURATION
# =============================================================================

datasets:
  
  # Dataset Tracking
  tracking:
    enabled: true
    project: "goat-prediction/goat-datasets"
    
  # Dataset Metadata
  metadata:
    sport: "${SPORT:-football}"
    date_range: "${DATE_RANGE:-2020-01-01_to_2023-12-31}"
    source: "${DATA_SOURCE:-statsbomb,opta,sportradar}"
    collection_method: "${COLLECTION_METHOD:-api}"
    
    # Statistics
    num_samples: ${NUM_SAMPLES:-10000}
    num_features: ${NUM_FEATURES:-100}
    missing_values_percentage: ${MISSING_VALUES_PERCENTAGE:-0.05}
    class_balance: "${CLASS_BALANCE:-balanced}"
    
    # Quality Metrics
    data_quality_score: ${DATA_QUALITY_SCORE:-0.95}
    completeness_score: ${COMPLETENESS_SCORE:-0.98}
    consistency_score: ${CONSISTENCY_SCORE:-0.97}
    
    # Processing Info
    preprocessing_steps:
      - "missing_value_imputation"
      - "feature_scaling"
      - "outlier_detection"
      - "feature_engineering"
      
    splits:
      train: ${TRAIN_SPLIT:-0.7}
      validation: ${VAL_SPLIT:-0.15}
      test: ${TEST_SPLIT:-0.15}
  
  # Dataset Artifacts
  artifacts:
    
    # Raw Data
    raw_data:
      path: "./data/raw/${SPORT}_matches.csv"
      description: "Raw match data"
      format: "csv"
      size_mb: "${RAW_DATA_SIZE_MB}"
      
    # Processed Data
    processed_features:
      path: "./data/processed/${SPORT}_features.npy"
      description: "Processed features"
      format: "numpy"
      
    processed_labels:
      path: "./data/processed/${SPORT}_labels.npy"
      description: "Processed labels"
      format: "numpy"
      
    # Dataset Reports
    data_report:
      path: "./reports/${SPORT}_data_report.html"
      description: "Dataset analysis report"
      format: "html"
      
    feature_report:
      path: "./reports/${SPORT}_feature_report.pdf"
      description: "Feature analysis report"
      format: "pdf"
      
    # Data Splits
    train_split:
      path: "./data/splits/${SPORT}_train.pkl"
      description: "Training split indices"
      format: "pickle"
      
    val_split:
      path: "./data/splits/${SPORT}_val.pkl"
      description: "Validation split indices"
      format: "pickle"
      
    test_split:
      path: "./data/splits/${SPORT}_test.pkl"
      description: "Test split indices"
      format: "pickle"

# =============================================================================
# HYPERPARAMETER OPTIMIZATION CONFIGURATION
# =============================================================================

hyperparameter_optimization:
  
  # Optimization Settings
  enabled: true
  framework: "optuna"  # optuna, hyperopt, ray
  
  # Study Configuration
  study:
    name: "${STUDY_NAME:-goat-${SPORT}-${MARKET_TYPE}-optimization}"
    direction: "maximize"
    storage: "sqlite:///./studies/${SPORT}_study.db"
    load_if_exists: true
    
  # Search Space
  search_space:
    
    # Model Architecture
    hidden_size:
      type: "int"
      low: 128
      high: 512
      step: 64
      
    num_layers:
      type: "int"
      low: 2
      high: 8
      
    num_heads:
      type: "int"
      low: 4
      high: 16
      step: 2
      
    dropout_rate:
      type: "float"
      low: 0.0
      high: 0.5
      
    # Training Parameters
    learning_rate:
      type: "float"
      low: 0.0001
      high: 0.01
      log: true
      
    batch_size:
      type: "categorical"
      values: [16, 32, 64, 128]
      
    weight_decay:
      type: "float"
      low: 0.0
      high: 0.1
      log: true
      
    # Data Parameters
    sequence_length:
      type: "int"
      low: 5
      high: 20
      
    feature_set:
      type: "categorical"
      values: ["basic", "advanced", "extended"]
  
  # Optimization Parameters
  optimization:
    n_trials: ${N_TRIALS:-100}
    timeout: ${TIMEOUT:-3600}
    n_jobs: ${N_JOBS:-4}
    show_progress_bar: true
    
    # Early Stopping
    early_stopping:
      enabled: true
      patience: 10
      min_delta: 0.001
      
    # Pruning
    pruning:
      enabled: true
      algorithm: "median"
      n_warmup_steps: 5
      interval_steps: 1
  
  # Metrics for Optimization
  metrics:
    primary: "val_f1"
    secondary:
      - "val_accuracy"
      - "val_auc"
      - "test_accuracy"
      - "roi"
      
    constraints:
      - name: "model_size_mb"
        condition: "<="
        value: 500
        
      - name: "inference_latency_ms"
        condition: "<="
        value: 100

# =============================================================================
# VISUALIZATION CONFIGURATION
# =============================================================================

visualization:
  
  # Charts Configuration
  charts:
    
    # Training Charts
    loss_chart:
      enabled: true
      title: "Training and Validation Loss"
      x_axis: "epoch"
      y_axis: "loss"
      series:
        - "train/loss"
        - "val/loss"
      smoothing: 0.9
      
    accuracy_chart:
      enabled: true
      title: "Training and Validation Accuracy"
      x_axis: "epoch"
      y_axis: "accuracy"
      series:
        - "train/accuracy"
        - "val/accuracy"
        
    # Metrics Charts
    metrics_chart:
      enabled: true
      title: "Classification Metrics"
      x_axis: "epoch"
      y_axis: "score"
      series:
        - "val/precision"
        - "val/recall"
        - "val/f1"
        
    # Business Metrics Charts
    business_chart:
      enabled: true
      title: "Business Metrics"
      x_axis: "epoch"
      y_axis: "value"
      series:
        - "business/roi"
        - "business/win_rate"
        - "business/profit_factor"
        
    # Feature Importance
    feature_importance_chart:
      enabled: true
      title: "Top 20 Feature Importance"
      type: "horizontal_bar"
      top_n: 20
      
    # Confusion Matrix
    confusion_matrix:
      enabled: true
      title: "Confusion Matrix"
      normalize: true
      include_values: true
      
    # ROC Curve
    roc_curve:
      enabled: true
      title: "ROC Curve"
      include_auc: true
      
    # Precision-Recall Curve
    precision_recall_curve:
      enabled: true
      title: "Precision-Recall Curve"
      include_ap: true
      
    # Calibration Curve
    calibration_curve:
      enabled: true
      title: "Calibration Curve"
      
    # Profit Curve
    profit_curve:
      enabled: true
      title: "Profit Curve"
      x_axis: "threshold"
      y_axis: "cumulative_profit"
  
  # Dashboard Configuration
  dashboard:
    
    # Layout
    layout: "custom"
    refresh_interval: 30  # seconds
    
    # Default View
    default_view: "experiment_summary"
    
    # Custom Views
    views:
      
      # Training View
      training_view:
        name: "Training Metrics"
        charts:
          - "loss_chart"
          - "accuracy_chart"
          - "metrics_chart"
          
      # Business View
      business_view:
        name: "Business Impact"
        charts:
          - "business_chart"
          - "profit_curve"
          - "roi_over_time"
          
      # Analysis View
      analysis_view:
        name: "Model Analysis"
        charts:
          - "feature_importance_chart"
          - "confusion_matrix"
          - "roc_curve"
          - "precision_recall_curve"
          
      # Comparison View
      comparison_view:
        name: "Experiment Comparison"
        compare_by:
          - "parameters/model/type"
          - "parameters/training/learning_rate"
          - "parameters/data/sport"
          
  # Report Generation
  reports:
    
    # Experiment Summary
    experiment_summary:
      enabled: true
      format: "html"
      template: "./templates/experiment_summary.html"
      output_path: "./reports/${EXPERIMENT_ID}_summary.html"
      
    # Model Card
    model_card:
      enabled: true
      format: "markdown"
      template: "./templates/model_card.md"
      output_path: "./reports/${MODEL_NAME}_card.md"
      
    # Performance Report
    performance_report:
      enabled: true
      format: "pdf"
      template: "./templates/performance_report.html"
      output_path: "./reports/${MODEL_NAME}_performance.pdf"

# =============================================================================
# MONITORING & ALERTING CONFIGURATION
# =============================================================================

monitoring:
  
  # Experiment Monitoring
  experiments:
    enabled: true
    check_interval: 300  # seconds
    
    # Metrics to Monitor
    metrics:
      - name: "train/loss"
        condition: "is_nan"
        action: "stop"
        
      - name: "val/accuracy"
        condition: "<"
        threshold: 0.5
        action: "alert"
        
      - name: "training_time_hours"
        condition: ">"
        threshold: 24
        action: "alert"
        
    # Resource Monitoring
    resources:
      - name: "gpu_memory_usage"
        threshold: 0.9
        action: "warning"
        
      - name: "cpu_usage"
        threshold: 0.8
        action: "warning"
        
      - name: "disk_space"
        threshold: 0.9
        action: "critical"
  
  # Model Monitoring
  models:
    enabled: true
    
    # Performance Monitoring
    performance:
      check_interval: 3600  # seconds
      
      metrics:
        - name: "inference_latency_p95"
          threshold: 100  # ms
          action: "warning"
          
        - name: "prediction_accuracy"
          threshold: 0.70
          action: "warning"
          
        - name: "throughput_rps"
          threshold: 100
          action: "warning"
          
        - name: "error_rate"
          threshold: 0.05
          action: "critical"
    
    # Data Drift Detection
    data_drift:
      enabled: true
      check_interval: 86400  # seconds (daily)
      
      methods:
        - "kolmogorov_smirnov"
        - "population_stability_index"
        - "maximum_mean_discrepancy"
        
      features:
        - "all"
        
      thresholds:
        psi:
          warning: 0.10
          critical: 0.25
          
        ks_statistic:
          warning: 0.05
          critical: 0.10
    
    # Model Drift Detection
    model_drift:
      enabled: true
      check_interval: 86400
      
      methods:
        - "accuracy_drop"
        - "prediction_distribution"
        - "performance_degradation"
        
      thresholds:
        accuracy_drop:
          warning: 0.05
          critical: 0.10
  
  # Alerting Configuration
  alerting:
    enabled: true
    
    # Notification Channels
    channels:
      
      # Slack
      slack:
        enabled: true
        webhook_url: "${SLACK_WEBHOOK_URL}"
        channel: "#ml-alerts"
        username: "GOAT-PREDICTION Monitor"
        
      # Email
      email:
        enabled: true
        smtp_server: "${SMTP_SERVER}"
        smtp_port: "${SMTP_PORT}"
        sender: "${ALERT_EMAIL_SENDER}"
        recipients:
          - "ml-team@goat-prediction.com"
          - "operations@goat-prediction.com"
          
      # Webhook
      webhook:
        enabled: false
        url: "${ALERT_WEBHOOK_URL}"
        
    # Alert Levels
    levels:
      info:
        enabled: true
        channels: ["slack"]
        
      warning:
        enabled: true
        channels: ["slack", "email"]
        
      critical:
        enabled: true
        channels: ["slack", "email", "webhook"]
        repeat_interval: 300  # seconds

# =============================================================================
# COLLABORATION CONFIGURATION
# =============================================================================

collaboration:
  
  # Team Settings
  team:
    name: "goat-prediction-team"
    members:
      - name: "${USER_NAME}"
        role: "data_scientist"
        email: "${USER_EMAIL}"
        
    roles:
      data_scientist:
        permissions:
          - "read"
          - "write"
          - "comment"
          
      ml_engineer:
        permissions:
          - "read"
          - "write"
          - "deploy"
          
      domain_expert:
        permissions:
          - "read"
          - "comment"
          
      product_manager:
        permissions:
          - "read"
          - "dashboard"
    
  # Sharing Settings
  sharing:
    
    # Public Sharing
    public: false
    
    # Team Sharing
    teams:
      - name: "goat-prediction-team"
        access_level: "full"
        
    # External Sharing
    external:
      enabled: false
      token_expiry_days: 7
    
    # Export Options
    export:
      formats:
        - "csv"
        - "json"
        - "html"
        - "pdf"
        
      include:
        - "parameters"
        - "metrics"
        - "artifacts"
        - "charts"
  
  # Comments & Discussions
  discussions:
    enabled: true
    
    # Comment Settings
    comments:
      notify_on_mention: true
      allow_attachments: true
      max_attachment_size_mb: 10
      
    # Discussion Boards
    boards:
      - name: "model_review"
        description: "Model review and approval discussions"
        
      - name: "bug_reports"
        description: "Bug reports and issues"
        
      - name: "feature_requests"
        description: "Feature requests and suggestions"
  
  # Review Workflow
  review:
    enabled: true
    
    # Review Stages
    stages:
      
      # Technical Review
      technical:
        required: true
        reviewers:
          - "data_scientist"
          - "ml_engineer"
        approval_threshold: 2
        
      # Business Review
      business:
        required: true
        reviewers:
          - "domain_expert"
          - "product_manager"
        approval_threshold: 1
        
      # Compliance Review
      compliance:
        required: ${ENVIRONMENT == "production"}
        reviewers:
          - "compliance_officer"
        approval_threshold: 1
    
    # Review Criteria
    criteria:
      
      technical:
        - name: "model_performance"
          threshold: 0.70
          
        - name: "inference_latency"
          threshold: 100
          
        - name: "model_size"
          threshold: 500
          
      business:
        - name: "expected_roi"
          threshold: 0.10
          
        - name: "risk_level"
          allowed_values: ["low", "medium"]
          
        - name: "compliance"
          required: true

# =============================================================================
# INTEGRATION CONFIGURATION
# =============================================================================

integrations:
  
  # ML Frameworks
  frameworks:
    
    # PyTorch
    pytorch:
      enabled: true
      version: "${PYTORCH_VERSION}"
      
      logging:
        gradients: true
        parameters: true
        activations: false
        histograms: true
        
      checkpointing:
        enabled: true
        frequency: 10  # epochs
        save_best_only: true
        monitor: "val/f1"
        
    # TensorFlow/Keras
    tensorflow:
      enabled: true
      version: "${TENSORFLOW_VERSION}"
      
      logging:
        graph: true
        histograms: true
        distributions: true
        
      callbacks:
        - "TensorBoard"
        - "ModelCheckpoint"
        - "EarlyStopping"
        
    # Scikit-learn
    sklearn:
      enabled: true
      
      logging:
        model: true
        metrics: true
        parameters: true
        
    # XGBoost
    xgboost:
      enabled: true
      
      logging:
        model: true
        importance: true
        metrics: true
        
    # LightGBM
    lightgbm:
      enabled: true
      
      logging:
        model: true
        importance: true
        
    # CatBoost
    catboost:
      enabled: true
      
      logging:
        model: true
        feature_importance: true
  
  # Data Processing
  data:
    
    # Pandas
    pandas:
      enabled: true
      
      logging:
        dataframes: true
        series: true
        statistics: true
        
    # NumPy
    numpy:
      enabled: true
      
      logging:
        arrays: false
        statistics: true
        
    # Dask
    dask:
      enabled: true
      
    # Ray
    ray:
      enabled: true
      
  # Visualization
  visualization:
    
    # Matplotlib
    matplotlib:
      enabled: true
      
      logging:
        figures: true
        auto_close: true
        
    # Plotly
    plotly:
      enabled: true
      
      logging:
        figures: true
        interactive: true
        
    # Seaborn
    seaborn:
      enabled: true
      
      logging:
        figures: true
        
  # Deployment
  deployment:
    
    # Docker
    docker:
      enabled: true
      
      logging:
        container_info: true
        resource_usage: true
        
    # Kubernetes
    kubernetes:
      enabled: true
      
      logging:
        pod_info: true
        resource_metrics: true
        
    # FastAPI
    fastapi:
      enabled: true
      
      logging:
        api_metrics: true
        request_logs: true
        
    # Streamlit
    streamlit:
      enabled: true
      
      logging:
        app_metrics: true
        user_interactions: true

# =============================================================================
# CUSTOM LOGGING CONFIGURATION
# =============================================================================

custom_logging:
  
  # Custom Loggers
  loggers:
    
    # CSV Logger
    csv:
      enabled: true
      path: "./logs/metrics.csv"
      flush_interval: 30
      include:
        - "metrics"
        - "parameters"
        - "metadata"
        
    # JSON Logger
    json:
      enabled: true
      path: "./logs/experiment.json"
      pretty_print: true
      include:
        - "all"
        
    # TensorBoard Logger
    tensorboard:
      enabled: true
      log_dir: "./logs/tensorboard"
      flush_secs: 30
      
    # MLflow Logger
    mlflow:
      enabled: true
      tracking_uri: "./mlruns"
      
    # Weights & Biases Logger
    wandb:
      enabled: false
      api_key: "${WANDB_API_KEY}"
      project: "goat-prediction"
      
  # Custom Handlers
  handlers:
    
    # Custom Metrics Handler
    custom_metrics:
      enabled: true
      metrics:
        
        # Business Metrics
        roi:
          formula: "(total_profit / total_investment) * 100"
          log_frequency: "epoch"
          
        sharpe_ratio:
          formula: "(average_return - risk_free_rate) / std_dev_returns"
          log_frequency: "epoch"
          
        profit_factor:
          formula: "gross_profit / gross_loss"
          log_frequency: "epoch"
          
        # Sports Metrics
        expected_value:
          formula: "(probability * odds - 1)"
          log_frequency: "batch"
          
        kelly_fraction:
          formula: "(probability * odds - 1) / (odds - 1)"
          log_frequency: "batch"
          
    # Custom Artifacts Handler
    custom_artifacts:
      enabled: true
      
      artifacts:
        
        # Model Analysis
        feature_importance:
          generate: true
          method: "shap"
          top_n: 20
          
        partial_dependence:
          generate: true
          features:
            - "home_rating"
            - "away_rating"
            - "home_form"
            - "away_form"
            
        # Data Analysis
        data_distribution:
          generate: true
          features:
            - "all"
            
        correlation_matrix:
          generate: true
          
    # Custom Charts Handler
    custom_charts:
      enabled: true
      
      charts:
        
        # Training Charts
        learning_rate_chart:
          enabled: true
          title: "Learning Rate Schedule"
          
        gradient_norm_chart:
          enabled: true
          title: "Gradient Norms"
          
        # Prediction Charts
        prediction_distribution:
          enabled: true
          title: "Prediction Distribution"
          
        confidence_calibration:
          enabled: true
          title: "Confidence Calibration"

# =============================================================================
# ENVIRONMENT SPECIFIC CONFIGURATION
# =============================================================================

# Development Environment
development:
  api_token: "${NEPTUNE_API_TOKEN_DEV}"
  project: "goat-prediction/goat-prediction-dev"
  mode: "async"
  flush_period: 5
  capture_stdout: true
  capture_stderr: true
  capture_hardware_metrics: true
  offline: false
  
  logging:
    level: "DEBUG"
    console: true
    file: "./logs/neptune_dev.log"
    
  monitoring:
    alerting: false

# Staging Environment
staging:
  api_token: "${NEPTUNE_API_TOKEN_STAGING}"
  project: "goat-prediction/goat-prediction-staging"
  mode: "async"
  flush_period: 10
  capture_stdout: true
  capture_stderr: true
  capture_hardware_metrics: true
  offline: false
  
  logging:
    level: "INFO"
    console: false
    file: "./logs/neptune_staging.log"
    
  monitoring:
    alerting: true
    channels: ["slack"]

# Production Environment
production:
  api_token: "${NEPTUNE_API_TOKEN_PROD}"
  project: "goat-prediction/goat-prediction-prod"
  mode: "sync"
  flush_period: 30
  capture_stdout: false
  capture_stderr: false
  capture_hardware_metrics: true
  offline: false
  
  logging:
    level: "WARNING"
    console: false
    file: "./logs/neptune_prod.log"
    
  monitoring:
    alerting: true
    channels: ["slack", "email", "webhook"]
    
  security:
    ssl_verify: true
    timeout: 30
    retries: 3

# =============================================================================
# TEMPLATE VARIABLES
# =============================================================================

# Runtime Variables
variables:
  TIMESTAMP: "${timestamp}"
  EXPERIMENT_ID: "${experiment_id}"
  MODEL_NAME: "${model_name}"
  SPORT: "${sport}"
  MARKET_TYPE: "${market_type}"
  ENVIRONMENT: "${environment}"
  
  # Git Variables
  GIT_COMMIT: "${git_commit}"
  GIT_BRANCH: "${git_branch}"
  GIT_TAG: "${git_tag}"
  
  # System Variables
  HOSTNAME: "${hostname}"
  USER: "${user}"
  CPU_COUNT: "${cpu_count}"
  GPU_COUNT: "${gpu_count}"
  
  # Sports Variables
  SEASON: "${season}"
  LEAGUE: "${league}"
  DATA_SOURCE: "${data_source}"
  
  # Model Variables
  MODEL_VERSION: "${model_version}"
  FRAMEWORK_VERSION: "${framework_version}"
  
  # Business Variables
  TARGET_ROI: "${target_roi}"
  RISK_TOLERANCE: "${risk_tolerance}"

# =============================================================================
# VALIDATION RULES
# =============================================================================

validation:
  
  # Parameter Validation
  parameters:
    
    # Model Parameters
    model:
      hidden_size:
        type: "int"
        min: 32
        max: 1024
        
      num_layers:
        type: "int"
        min: 1
        max: 12
        
      dropout_rate:
        type: "float"
        min: 0.0
        max: 0.9
        
    # Training Parameters
    training:
      learning_rate:
        type: "float"
        min: 0.00001
        max: 0.1
        
      batch_size:
        type: "int"
        min: 1
        max: 1024
        
      max_epochs:
        type: "int"
        min: 1
        max: 1000
        
    # Data Parameters
    data:
      train_split:
        type: "float"
        min: 0.5
        max: 0.9
        
      sequence_length:
        type: "int"
        min: 1
        max: 100
        
  # Metric Validation
  metrics:
    
    # Performance Metrics
    accuracy:
      min: 0.0
      max: 1.0
      
    loss:
      min: 0.0
      
    # Business Metrics
    roi:
      min: -1.0
      max: 10.0
      
    win_rate:
      min: 0.0
      max: 1.0
      
  # Resource Validation
  resources:
    
    # Memory Validation
    memory:
      max_usage_gb: 32
      action: "warning"
      
    # GPU Validation
    gpu:
      max_memory_gb: 24
      action: "warning"
      
    # Disk Validation
    disk:
      min_free_gb: 10
      action: "critical"

# =============================================================================
# DOCUMENTATION & EXAMPLES
# =============================================================================

documentation:
  
  # Configuration Examples
  examples:
    
    # Basic Example
    basic: |
      import neptune
      from neptune import Run
      
      # Initialize run
      run = Run(
          project="goat-prediction/goat-prediction-ultimate",
          api_token=os.environ["NEPTUNE_API_TOKEN"],
          tags=["football", "match_winner", "development"]
      )
      
      # Log parameters
      run["parameters"] = {
          "learning_rate": 0.001,
          "batch_size": 32,
          "model_type": "transformer"
      }
      
      # Log metrics during training
      for epoch in range(100):
          train_loss = calculate_loss()
          val_accuracy = calculate_accuracy()
          
          run["train/loss"].append(train_loss)
          run["val/accuracy"].append(val_accuracy)
      
      # Log model
      run["model"].upload("./models/football_model.pt")
      
      # Stop run
      run.stop()
    
    # PyTorch Integration
    pytorch_example: |
      import torch
      import neptune
      from neptune.integrations.pytorch import NeptuneLogger
      
      # Create Neptune logger
      neptune_logger = NeptuneLogger(
          run=run,
          base_namespace="training",
          log_model_diagnostics=True
      )
      
      # Use with PyTorch Lightning
      trainer = pl.Trainer(
          logger=neptune_logger,
          max_epochs=100,
          callbacks=[pl.callbacks.ModelCheckpoint(dirpath="./checkpoints")]
      )
      
      trainer.fit(model, train_loader, val_loader)
    
    # Hyperparameter Optimization
    optimization_example: |
      import neptune
      from neptune.integrations.optuna import NeptuneCallback
      
      # Create Neptune callback for Optuna
      neptune_callback = NeptuneCallback(
          run=run,
          base_namespace="optimization"
      )
      
      # Create Optuna study
      study = optuna.create_study(
          direction="maximize",
          study_name="goat-optimization",
          storage="sqlite:///goat_study.db",
          load_if_exists=True
      )
      
      # Run optimization
      study.optimize(
          objective_function,
          n_trials=100,
          callbacks=[neptune_callback]
      )
    
    # Model Registry Example
    registry_example: |
      import neptune
      from neptune import init_model_version
      
      # Initialize model version
      model_version = init_model_version(
          model="GOAT-FOOTBALL-MATCH-WINNER",
          project="goat-prediction/goat-model-registry"
      )
      
      # Log model metadata
      model_version["metadata"] = {
          "framework": "pytorch",
          "task": "classification",
          "sport": "football",
          "market": "match_winner"
      }
      
      # Upload model files
      model_version["model"].upload("./models/football_model.pt")
      model_version["config"].upload("./configs/model_config.yaml")
      
      # Log performance metrics
      model_version["metrics"] = {
          "accuracy": 0.85,
          "f1_score": 0.83,
          "roi": 0.18
      }
      
      # Promote to production
      model_version.change_stage("production")

# =============================================================================
# SECURITY & COMPLIANCE
# =============================================================================

security:
  
  # Authentication
  authentication:
    method: "api_token"
    token_refresh_interval: 3600  # seconds
    
  # Encryption
  encryption:
    enabled: true
    algorithm: "aes-256-gcm"
    
  # Network Security
  network:
    ssl_verify: true
    timeout: 30
    retries: 3
    
    proxy:
      enabled: ${PROXY_ENABLED:-false}
      http: "${HTTP_PROXY}"
      https: "${HTTPS_PROXY}"
      
  # Data Privacy
  privacy:
    
    # Sensitive Data
    mask_sensitive_data: true
    sensitive_fields:
      - "api_key"
      - "password"
      - "secret"
      - "token"
      
    # Data Retention
    retention_policy:
      experiments: "365d"
      models: "730d"
      datasets: "1095d"
      
    # GDPR Compliance
    gdpr_compliant: true
    data_anonymization: true
    
  # Access Control
  access_control:
    
    # IP Whitelisting
    ip_whitelist:
      enabled: ${IP_WHITELIST_ENABLED:-false}
      addresses:
        - "10.0.0.0/8"
        - "192.168.0.0/16"
        
    # API Rate Limiting
    rate_limiting:
      enabled: true
      requests_per_minute: 60
      
    # Audit Logging
    audit_logging:
      enabled: true
      log_file: "./logs/security_audit.log"

# =============================================================================
# BACKUP & RECOVERY
# =============================================================================

backup:
  
  # Backup Configuration
  enabled: true
  
  # Local Backup
  local:
    enabled: true
    directory: "./backups/neptune"
    retention_days: 30
    compression: true
    
  # Cloud Backup
  cloud:
    enabled: false
    provider: "s3"  # s3, gcs, azure
    bucket: "${BACKUP_BUCKET}"
    region: "${BACKUP_REGION}"
    retention_days: 90
    
  # Backup Schedule
  schedule:
    frequency: "daily"
    time: "02:00"
    
  # Backup Content
  content:
    experiments: true
    models: true
    datasets: true
    metadata: true
    
  # Recovery
  recovery:
    test_frequency: "weekly"
    recovery_time_objective: "4h"  # 4 hours
    recovery_point_objective: "24h" # 24 hours

# =============================================================================
# END OF CONFIGURATION
# =============================================================================

# Note: This configuration file is part of GOAT-PREDICTION Ultimate
# For questions or issues, contact: ml-team@goat-prediction.com
