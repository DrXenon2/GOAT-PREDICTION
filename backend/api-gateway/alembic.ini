# backend/api-gateway/alembic.ini
# Configuration file for Alembic migrations for Goat Prediction Ultimate API Gateway

# Meta configuration
[alembic]
# Path to the migration scripts
script_location = alembic

# Template used to generate migration files
# using 'async' template for async SQLAlchemy
file_template = %%(year)d%%(month).2d%%(day).2d_%%(hour).2d%%(minute).2d%%(second).2d_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
timezone = UTC

# Truncate length of revision identifier
truncate_revision_length = 40

# Max length of revision identifier comment
revision_identifier_max_length = 80

# Format used to generate revision identifiers
revision_identifier_format = %(slug)s_%(year)d%(month).2d%(day).2d%(hour).2d%(minute).2d%(second).2d

# Hook scripts
post_write_hooks = black
post_write_hooks_black = {"type": "console_scripts", "entrypoint": "black", "options": ["-l", "88", "-t", "py311"]}

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

# Database configuration section
# Multiple databases can be configured using format [database_<name>]
[databases]
# Default database
default = postgresql+asyncpg://postgres:postgres@localhost:5432/goat_prediction_api

# Test database
test = postgresql+asyncpg://postgres:postgres@localhost:5433/goat_prediction_api_test

# Development database
dev = postgresql+asyncpg://${DB_USER:postgres}:${DB_PASSWORD:postgres}@${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:goat_prediction_api_dev}

# Production database (uses environment variables)
prod = postgresql+asyncpg://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

# Database configuration for the main application
[database_main]
# SQLAlchemy database URL
# Uses asyncpg driver for async support
sqlalchemy.url = ${databases:${ENVIRONMENT:dev}}

# Maximum pool size
pool_size = 20

# Pool recycle time (seconds)
pool_recycle = 3600

# Pool timeout (seconds)
pool_timeout = 30

# Enable connection pooling
pool_pre_ping = true

# Echo SQL (only in development)
echo = ${ECHO_SQL:false}

# Migration settings
[migration]
# Should the migration process create the database if it doesn't exist?
create_database = true

# Should we drop the database before creating?
drop_database_first = false

# Should we run migrations in a transaction?
transaction_per_migration = true

# Should we output SQL instead of running migrations?
sql = false

# Tag to apply to migrations
tag = ${MIGRATION_TAG:}

# Target metadata
target_metadata = src.models.metadata

# Version table settings
[version_table]
# Name of the version table
table_name = alembic_version

# Schema for version table (if using schemas)
schema = public

# Include schema name in version table
include_schema = false

# Version length
version_length = 32

# Version separator
version_separator = _

# Migration environment settings
[environment]
# Environment name (dev, test, prod)
name = ${ENVIRONMENT:dev}

# Debug mode
debug = ${DEBUG:false}

# Testing mode
testing = ${TESTING:false}

# Feature flags
[features]
# Use batch operations for SQLite (irrelevant for PostgreSQL)
batch_operations = false

# Use two-phase commit
two_phase_commit = false

# Support alter table operations
alter_table = true

# Support schemas
schemas = true

# Support auto-generate
autogenerate = true

# Support compare types
compare_type = true

# Support compare server default
compare_server_default = true

# Performance settings
[performance]
# Use bulk inserts for data migrations
bulk_insert = true

# Batch size for bulk operations
batch_size = 1000

# Timeout for database operations (seconds)
timeout = 300

# Retry configuration for database operations
max_retries = 3
retry_delay = 1

# Migration naming conventions
[naming_conventions]
# Format for constraint names
constraint = "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s"

# Format for index names
index = "ix_%(table_name)s_%(column_0_name)s"

# Format for unique constraint names
unique = "uq_%(table_name)s_%(column_0_name)s"

# Format for check constraint names
check = "ck_%(table_name)s_%(constraint_name)s"

# Format for primary key names
primary_key = "pk_%(table_name)s"

# Format for foreign key names
foreign_key = "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s"

# SQLAlchemy settings
[sqlalchemy]
# Engine settings
echo_pool = ${ECHO_POOL:false}

# Hide parameters in logs
hide_parameters = ${HIDE_PARAMETERS:false}

# Max overflow for connection pool
max_overflow = 10

# Connection arguments
connect_args = {"server_settings": {"jit": "off"}}

# JSON serialization settings
json_serializer = json.dumps
json_deserializer = json.loads

# Timezone settings
timezone = UTC

# Async settings for SQLAlchemy 2.0
[async]
# Use async driver
driver = asyncpg

# Async connection timeout (seconds)
connect_timeout = 30

# Command timeout (seconds)
command_timeout = 300

# Keepalive settings
keepalives_idle = 30
keepalives_interval = 10
keepalives_count = 5

# SSL settings
[ssl]
# Enable SSL
enable = ${DB_SSL:false}

# SSL mode
sslmode = ${DB_SSLMODE:prefer}

# SSL root certificate
sslrootcert = ${DB_SSLROOTCERT:}

# SSL certificate
sslcert = ${DB_SSLCERT:}

# SSL key
sslkey = ${DB_SSLKEY:}

# Migration hooks
[hooks]
# Pre-migration hooks
pre_migration = 
    # Check database connectivity
    "python -c \"import asyncio; from sqlalchemy.ext.asyncio import create_async_engine; import sys; engine = create_async_engine('${databases:${ENVIRONMENT:dev}}'); print('âœ“ Database connectivity check passed')\""

# Post-migration hooks
post_migration = 
    # Run data validation
    "python scripts/validate_migrations.py"
    
    # Update migration metadata
    "python scripts/update_migration_metadata.py"

# Post-write hooks (for generated migration files)
post_write = 
    # Format with black
    "black -l 88 -t py311 %(path)s"
    
    # Sort imports with isort
    "isort %(path)s"
    
    # Run type checking (mypy)
    "mypy --ignore-missing-imports %(path)s"

# Error handling
[error_handling]
# On migration conflict
conflict = stop

# On SQL error
sql_error = rollback

# On connection error
connection_error = retry

# Maximum retries for connection errors
max_connection_retries = 5

# Retry delay (seconds)
retry_delay = 2

# Custom configuration sections for Goat Prediction
[goat_prediction]
# Application name for database connections
application_name = goat-prediction-api-gateway

# Database schema
schema = public

# Migration strategy
strategy = versioned

# Version prefix
version_prefix = goat_

# Backup before migration
backup_before_migration = true

# Backup location
backup_location = ./.backups/database/migrations/

# Test migrations
test_migrations = true

# Test database
test_database = ${databases:test}

# Environment-specific overrides
[env:dev]
# Development environment overrides
databases.default = postgresql+asyncpg://postgres:postgres@localhost:5432/goat_prediction_api_dev
echo = true
debug = true
testing = false

[env:test]
# Test environment overrides
databases.default = postgresql+asyncpg://postgres:postgres@localhost:5433/goat_prediction_api_test
echo = false
debug = true
testing = true
transaction_per_migration = true

[env:staging]
# Staging environment overrides
databases.default = postgresql+asyncpg://${STAGING_DB_USER}:${STAGING_DB_PASSWORD}@${STAGING_DB_HOST}:${STAGING_DB_PORT}/${STAGING_DB_NAME}
echo = false
debug = false
testing = false
ssl.enable = true
ssl.sslmode = require

[env:production]
# Production environment overrides
databases.default = postgresql+asyncpg://${PROD_DB_USER}:${PROD_DB_PASSWORD}@${PROD_DB_HOST}:${PROD_DB_PORT}/${PROD_DB_NAME}
echo = false
debug = false
testing = false
transaction_per_migration = true
ssl.enable = true
ssl.sslmode = verify-full
error_handling.max_connection_retries = 10
performance.timeout = 600

# Migration tool configuration
[tool]
# Migration tool name
name = alembic

# Tool version
version = 1.13.1

# Python version requirements
python = ">=3.11"

# Dependencies
requires = 
    alembic>=1.13.1
    sqlalchemy>=2.0.0
    asyncpg>=0.29.0
    psycopg2-binary>=2.9.9
    python-dotenv>=1.0.0
    black>=23.0.0
    isort>=5.12.0
    mypy>=1.8.0

# Entry points
[entry_points]
console_scripts = 
    goat-migrate = alembic.config:main

# Plugin configuration
[plugin]
# Plugin directories
directories = 
    ./alembic/plugins

# Enabled plugins
enabled = 
    migration_validator
    schema_checker
    data_migrator

# Health check configuration
[health_check]
# Enable health checks
enabled = true

# Health check timeout (seconds)
timeout = 30

# Health check interval (seconds)
interval = 60

# Health check endpoints
endpoints = 
    database: ${databases:${ENVIRONMENT:dev}}/health
    migrations: ${databases:${ENVIRONMENT:dev}}/migrations/health

# Security configuration
[security]
# Encrypt migration files
encrypt_migrations = false

# Encryption key (base64)
encryption_key = ${MIGRATION_ENCRYPTION_KEY:}

# Sign migrations
sign_migrations = true

# Signing key
signing_key = ${MIGRATION_SIGNING_KEY:}

# Verify signatures
verify_signatures = true

# Audit logging
audit_logging = true

# Audit log location
audit_log = ./.logs/audit/migrations.log

# Monitoring configuration
[monitoring]
# Enable monitoring
enabled = true

# Monitoring backend (prometheus, statsd, datadog)
backend = prometheus

# Metrics prefix
prefix = goat_prediction_migrations_

# Export metrics
export_metrics = true

# Metrics port
port = 9095

# Metrics path
path = /metrics

# Alerting
alerting = true

# Alert thresholds
thresholds = 
    migration_duration_seconds = 300
    migration_failure_rate = 0.1
    database_connection_errors = 5

# Documentation
[documentation]
# Generate documentation
generate_docs = true

# Documentation format (markdown, html, pdf)
format = markdown

# Output directory
output_dir = ./docs/migrations/

# Include SQL
include_sql = true

# Include diagrams
include_diagrams = true

# Diagram format (png, svg, dot)
diagram_format = svg

# Template configuration
[template]
# Migration template
migration_template = |
    """
    ${up_revision} - ${down_revision}
    
    Revision ID: ${revision}
    Revises: ${down_revision}
    Create Date: ${create_date}
    
    ${message}
    """
    
    # Import types for type hints
    from typing import Sequence, Union
    
    from alembic import op
    import sqlalchemy as sa
    from sqlalchemy.dialects import postgresql
    
    # Revision identifiers, used by Alembic.
    revision: str = '${revision}'
    down_revision: Union[str, None] = '${down_revision}'
    branch_labels: Union[str, Sequence[str], None] = ${branch_labels}
    depends_on: Union[str, Sequence[str], None] = ${depends_on}
    
    ${imports if imports else ""}
    
    def upgrade() -> None:
        ${upgrades if upgrades else "pass"}
    
    
    def downgrade() -> None:
        ${downgrades if downgrades else "pass"}

# Post-migration validation template
validation_template = |
    """
    Validation script for revision: ${revision}
    """
    
    import asyncio
    from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
    from sqlalchemy.orm import sessionmaker
    import sys
    
    async def validate_migration():
        # Database URL from environment
        database_url = "${databases:${ENVIRONMENT:dev}}"
        
        # Create async engine
        engine = create_async_engine(database_url)
        
        async with engine.connect() as conn:
            # Add validation logic here
            print(f"Validating migration: ${revision}")
            
            # Example: Check if tables exist
            result = await conn.execute(
                sa.text("SELECT tablename FROM pg_tables WHERE schemaname = 'public'")
            )
            tables = result.scalars().all()
            print(f"Found {len(tables)} tables in public schema")
            
            # Add specific validation for this migration
            ${validation_logic if validation_logic else "# No specific validation logic"}
        
        await engine.dispose()
    
    if __name__ == "__main__":
        asyncio.run(validate_migration())

# Script location configuration
[script]
# Main script location
location = alembic

# Multiple script locations (for multiple databases)
locations = 
    main:alembic
    analytics:alembic/analytics
    bets:alembic/bets

# Output encoding
output_encoding = utf-8

# Version path separator
version_path_separator = os

# Recursive version locations
recursive_version_locations = false

# Version file template
version_file_template = versions/%%(slug)s

# Data migration configuration
[data_migration]
# Enable data migrations
enabled = true

# Data migration directory
directory = alembic/data_migrations

# Batch size for data migrations
batch_size = 1000

# Timeout for data migrations (seconds)
timeout = 3600

# Retry failed data migrations
retry_failed = true

# Max retries for data migrations
max_retries = 3

# Rollback on failure
rollback_on_failure = true

# Seed data configuration
[seed_data]
# Enable seed data
enabled = true

# Seed data directory
directory = alembic/seed_data

# Environment-specific seed data
environments = 
    dev: seed_data/dev/
    test: seed_data/test/
    staging: seed_data/staging/

# Run seed data after migrations
run_after_migrations = true

# Rollback seed data on failure
rollback_on_failure = true

# Migration groups
[groups]
# Group migrations by feature
feature_groups = 
    core: 
        - users
        - authentication
        - profiles
    betting: 
        - bets
        - odds
        - markets
    analytics: 
        - predictions
        - metrics
        - reports
    sports: 
        - football
        - basketball
        - tennis

# Group dependencies
dependencies = 
    core: []
    betting: [core]
    analytics: [core, betting]
    sports: [core]

# Migration order
order = 
    - core
    - sports
    - betting
    - analytics

# Final section with includes
[includes]
# Include other configuration files
files = 
    ./alembic/local.ini
    ./alembic/overrides.ini

# Environment variable expansion
[env_expansion]
# Enable environment variable expansion
enabled = true

# Default values for environment variables
defaults = 
    DB_USER: postgres
    DB_PASSWORD: postgres
    DB_HOST: localhost
    DB_PORT: 5432
    DB_NAME: goat_prediction_api
    ENVIRONMENT: dev
    DEBUG: false
    TESTING: false

# Required environment variables
required = 
    - DB_USER
    - DB_PASSWORD
    - DB_HOST
    - DB_PORT
    - DB_NAME

# Validation
[validation]
# Validate configuration on load
validate_on_load = true

# Validate database URL
validate_database_url = true

# Validate migration scripts
validate_migrations = true

# Validate dependencies
validate_dependencies = true

# Warning thresholds
warnings = 
    missing_down_revision: true
    empty_migration: true
    long_running_migration: 60
    large_migration: 1000

# This is the end of the alembic.ini configuration file
# For Goat Prediction Ultimate API Gateway
# Version: 1.0.0
# Generated: 2026-01-24
